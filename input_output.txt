Строим две нейросети: policy_head и value_head

На вход обоих нейросетей подадим:
1)контекст доски:
вид: двумерный вектор 64х12
(8 векторов для 8 рядов)
(внутри каждого ряда 8 векторов для каждой клетки)
(внутри каждой клетки 12 цифр для обозначения фигуры и цвета через one-hot-encoding)

2) цвет игрока (0-черный, 1-белый)


На выходе policy_head получим:
самый наилучший ход для этого игрока при данной на входе (текущей) позиции
всего возможных ходов с каждого из 64 клеток в 63 возможных клеток
(с одной клетки на самого себя невозможно, а на остальные 63 пойдет), а еще 4 рокировок,
а также 44 возможных перемещений пешек в самый край к оппненту с 4мя возможными превращениями (Q,N,B,R)
64х63 + 4 + 44x4 = 4212 ходов
получим индекс самого лучшего хода (вероятностное распределение в пределах от 0 до 1)

На выходе value_head получим:
оценку заданной на вход контекста доски для игрока
число от -1 до 1
1 - идеальное выгодное состояние для игрока (худшее для оппонента)
-1  - самое худшее состояние (выгодное для оппонента)